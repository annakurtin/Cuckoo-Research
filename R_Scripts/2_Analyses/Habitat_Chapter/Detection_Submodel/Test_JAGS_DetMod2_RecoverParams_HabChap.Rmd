---
title: "Test JAGS Model 2 on Simulated Data"
author: "Anna Kurtin"
date: "6/3/2024"
output: html_document
---


```{r setup, include=FALSE}
#Anna's note: I copied over the original markdown (labeled with model 1) to include the fixed model that Thomas and I created.
knitr::opts_chunk$set(echo = TRUE)
library(jagsUI)
library(tidyverse)
library(jagshelper)
library(ggplot2)
library(extraDistr)
source("C:/Users/annak/OneDrive/Documents/UM/Research/Coding_Workspace/Cuckoo-Research/R_Scripts/5_Visualization/Create_HexCodes_CuckooColorBlind.R")
# set.seed(123)
# sample(1:5,5)
# set.seed(123)
# sample(1:5,5)
# Have to set the seed before each one
# So why does this give me a different slection of numbers each time?
```

In order to determine if my model will perform well, I will first be simulating data using specified values for probability of occupancy and probability of detection. Then I will run my detection sub model on that data to see if it can recover the correct parameters. 

I am simulating this data with a 20% probability of occupancy (based on naive estimates from our data) and a probability of detection of 60% (fairly high, so that we can test our model performance). 

## Generate Data

```{R generate data, out.width = "50%", out.height = "50%"}
# b1/cov1: date - uniform, survey level
# b2/cov2: veg density - normal, site level
# b3/cov3: background noise - normal, survey level
# b4/cov4: effort - normal - survey level 

nP <- 107  # number of points
nV <- 6    # number of repeated visits
nC <- 4    # number of covariates
#survey_covs <- 3

# create latent state (z) and detection (y) data storage
z <- NULL        # point-level latent state
y <- array(NA, dim = c(nP, nV))   # point-level observation data

# create separate arrays for each covariate and fill with randomly generated data
date_cov <- array(NA, dim = c(nP,nV))
set.seed(1)
dates <- runif(nV, -2,2) # Pull six (standardized) values for date
for (d in 1:nV){
  date_cov[,d] <- dates[d]
}
hist(date_cov, col = cuckoo_palette[1], main = "Distribution of Scaled Date")

# Fill in veg density
set.seed(2)
veg_cov <- rnorm(nP, 0, 1)
hist(veg_cov, col = cuckoo_palette[1], main = "Distribution of Simulated Scaled Veg Density")

# Fill in background noise
db_cov <- array(NA, dim = c(nP,nV))
set.seed(3)
for (i in 1:nP){
  for (j in 1:nV){
    db_cov[i,j] <- rnorm(1, 0, 1)
  }
}
hist(db_cov, col = cuckoo_palette[1], main = "Distribution of Simulated Scaled Background Noise")

# Fill in effort
effort_cov <- array(NA, dim = c(nP,nV))
set.seed(4)
for (i in 1:nP){
  for (j in 1:nV){
    effort_cov[i,j] <- rnorm(1, 0, 1)
  }
}
hist(effort_cov, col = cuckoo_palette[1], main = "Distribution of Simulated Scaled Effort")

# covariate effects (pull randomly for each covariate)
set.seed(5)
beta <- rnorm(nC, 0, 1)

psi0 <- qlogis(0.2) # probability of presence
p0 <- qlogis(0.6) # probability of detection

psi <- NULL
for (i in 1:nP){
  psi[i] = plogis(psi0)
}
# Assume equal probability of presence at all sites with this simulation

# get your true presence/non presence values from psi
set.seed(8) # I changed this around until I got a value of presence/absence that looked good to me
z <- rbinom(nP, 1, psi)

# total number of detections across number of visits (nV)
y <- matrix(NA, nP, nV)
# fill in the detection matrix dependent on whether the animal was there (z) and whether it was detected (p0)
# add covariate effects here
set.seed(7)
for (i in 1:nP){
  for (j in 1:nV){
    y[i,j] <- rbinom(1, z[i], plogis(p0 + (beta[1]*date_cov[i,j]) + (beta[2]*veg_cov[i]) + (beta[3]*db_cov[i,j]) + (beta[4]*effort_cov[i,j])))
  }
}

# b1/beta[1] : date
# b2/beta[2] : vegetation density
# b3/beta[3] : db
# b4/beta[4] : effort
```

## Set up model 

Here is the model parameterization. This is the exact same as the model I run on my actual data, I've just included it here for reference. 

```{R Set Up Model,eval = FALSE}
cat("
  model{
    # Loop through each sampling unit
    for(i in 1:n_unit){
      Z[i] ~ dbern(psi[i])  # Presence or absence drawn from a bernoulli distribution with occupancy probability psi  
      logit(psi[i]) <- a0
      
      cov2[i] ~ dnorm(0, 1) # Assuming normal distribution for missing covariates
      
      for(j in 1:n_rep){
        cov1[i,j] ~ dnorm(0, 1) # Assuming normal distribution for missing covariates
        cov3[i,j] ~ dnorm(0, 1) # Assuming normal distribution for missing covariates
        cov4[i,j] ~ dnorm(0, 1) # Assuming normal distribution for missing covariates
        
        det_data[i,j] ~  dbern(Z[i]*theta[i,j])  # Create detection data drawn from a bernoulli distribution incorporating the true presence (Z) with probability of detection theta
        logit(theta[i,j]) <- b0 + b1*cov1[i,j] + b2*cov2[i] + b3*cov3[i,j] + b4*cov4[i,j]
        
      }
    }
    
    # Priors
    a0 ~ dlogis(0, 1)
    b0 ~ dlogis(0, 1)
    b1 ~ dnorm(0, 1)
    b2 ~ dnorm(0, 1)
    b3 ~ dnorm(0, 1)
    b4 ~ dnorm(0, 1)
  }
  ", file = "./R_Scripts/2_Analyses/Habitat_Chapter/Detection_Submodel/Model_Structure_Files/Test_JAGS_Occ_DetectionModel2.txt")
```

Next, I establish the parameters for running the model itself. I specify first the number of chains, which is the number of times that JAGS will create independent posterior distributions. The use of multiple chains is to ensure that they arrive to the same conclusion - they are "evenly mixed" as we will see in the traceplots. Next, I specify the total number of iterations. This is the number of times the MCMC sampler will run and draw new posterior values. Next, I specify the burnin period, which is the number of iterations JAGS will "throw out" before keeping the posterior draws in the chain. This is becuase we randomize our starting/initial values for the each covariate, so if one of these initial values is very far off, the MCMC sampler will have some time to get it into a more normal range before we actually start monitoring the chains. Finally, I specify the number of thinning. This means that the MCMC sampler will keep every other value it draws from the posterior distribution. Thinning the chains in this way reduces the amount of correlation between values in the posterior distribution and increases their independence. 

```{R Picking Apart the Model}
# What do density functions do in R??
# Bernoulli distribution functions: https://www.geeksforgeeks.org/bernoulli-distribution-in-r/
#library(Rlab)
x <- c(0,1,3,5,7,10) # Establish a vector of quantiles
y <- dbern(x, prob = 0.5) # Obtain the corresponding probability density function, specifying the probability of success on each trial 
plot(x,y, type = "o")
```

```{R Establish Parameters for Running Models}
# sampler settings that I use in my main model
nc <- 3 # number of chains
ni <- 20000 # number of iterations
nb <- 4000 # number burnin
nt <- 2 # number of thinning
```

Next, I package the data together for JAGS to use. I also specify the initial values for the covariate effects and intercepts, which are all drawn from a standard normal distribution. I call the model and specify which values I want it to monitor. 

```{R Fit Model, eval = FALSE}
# Create a list of data for JAGS
jags_data <- list(
  # True presence at sites with confirmed presences
  Z = z,
  # Detection/nondetection data
  det_data = y,
  # Date
  cov1 = date_cov,
  # Veg Density - site level
  cov2 = veg_cov,
  # Background noise
  cov3 = db_cov,
  # Effort 
  cov4 = effort_cov,
  n_unit = nP,
  n_rep = nV
)

# Set initial values (optional)
init_func <- function(){
  list(
    a0 = rnorm(1, 0, 1),
    b0 = rnorm(1, 0, 1),
    b1 = rnorm(1, 0, 1),
    b2 = rnorm(1, 0, 1),
    b3 = rnorm(1, 0, 1),
    b4 = rnorm(1, 0, 1)
  )
}

# Run JAGS model on the same model we specify in the Fit_JAGS_Detection_Model2_HabChap markdown
sim_fit1 <- jags(data = jags_data, 
                 model.file = "./R_Scripts/2_Analyses/Habitat_Chapter/Detection_Submodel/Model_Structure_Files/JAGS_HabDetMod2.txt",
                 parameters.to.save = c("a0", "b0", "b1", "b2", "b3", "b4"),
                 n.iter = ni, 
                 n.burnin = nb, 
                 n.chains = nc,
                 n.thin = nt,
                 parallel = TRUE,
                 inits = init_func)
#saveRDS(sim_fit1, file = "./R_Scripts/2_Analyses/Habitat_Chapter/Detection_Submodel/Models_Ran_Outputs/Simulations/Test_JAGS_RecoverParams_GlobalDetMod2.Rdata")
```

## Model outputs from Simulated Data and Parameters 

Now let's look at the output of this model. What I'm looking for here is to see if my model converged (meaning that it is specified correctly and the simulated data makes sense) and whether or not it was able to recover the parameters I used to generate the data. 
```{R Evaluate Convergence Sim1}
# Read in the model that we saved after running the above code
sim_fit1 <- readRDS("C:/Users/annak/OneDrive/Documents/UM/Research/Coding_Workspace/Cuckoo-Research/R_Scripts/2_Analyses/Habitat_Chapter/Detection_Submodel/Models_Ran_Outputs/Simulations/Test_JAGS_RecoverParams_GlobalDetMod2.Rdata")

# Evaluate convergence
print(sim_fit1)
# plot traceplots
tracedens_jags(sim_fit1, parmfrow = c(3,3))
```

It looks like this model converged nicely. Let's check and see if it effectively recovered the parameters. I'm going to take a look at the values themselves, then plot the true values on top of the posterior distribution to see how close to the center they are. 
```{R Evaluate Outputs Sim1}
# Get a summary of the results
summary(sim_fit1)
# Did we recover our parameters?
beta
```
```{R Plot Chains Sim1}
# Plot posterior distribution
jags_chains1 <- jags_df(sim_fit1)

chains_viol1 <- jags_chains1 %>% select(b1,b2,b3,b4)
colnames(chains_viol1) <- c("date","veg_density","background_noise","effort")
true_vals <- data.frame(beta,covariate=c("date","veg_density","background_noise","effort"))
chains_viol_long1 <- chains_viol1 %>% pivot_longer(cols = c("date","veg_density","background_noise","effort"),names_to = "Parameter", values_to = "Values")

# Create the violin plot
plot1 <- ggplot() +
  geom_violin(data=chains_viol_long1, aes(x = Parameter, y = Values,fill = Parameter),trim = FALSE) +
  labs(title = "Posterior Distributions and True Parameters") +
  scale_fill_manual(values = c("date"=palette_5[1], "background_noise"=palette_5[2], "effort" = palette_5[3], "veg_density" = palette_5[4])) + theme(axis.text.x = element_blank())+
  geom_point(data = true_vals, aes(x=covariate, y = beta))+
  theme_minimal()
plot1
```

So it looks like my model is performing fairly well on the data I simulated. The only parameter that was not well recovered was vegetation density, but the true value still fell within the 95% credible interval. This could have been because the simulated data for vegetation density was the most "non normal" out of all of them. 

```{R Veg Density Estimate, include = FALSE, eval = FALSE}
# Let's try to run this on vegetation data that is more "normal" looking.
# Fill in veg density
set.seed(123)
veg_cov_normal <- rnorm(nP, 0, 1)
hist(veg_cov_normal, col = cuckoo_palette[1], main = "Distribution of Simulated Scaled Veg Density")

# Create a list of data for JAGS
jags_data_vegnorm <- list(
  # True presence at sites with confirmed presences
  Z = z,
  # Detection/nondetection data
  det_data = y,
  # Date
  cov1 = date_cov,
  # Veg Density - site level
  cov2 = veg_cov_normal,
  # Background noise
  cov3 = db_cov,
  # Effort 
  cov4 = effort_cov,
  n_unit = nP,
  n_rep = nV
)

# Run JAGS model on the same model we specify in the Fit_JAGS_Detection_Model2_HabChap markdown
sim_fit1.5 <- jags(data = jags_data_vegnorm, 
                 model.file = "./R_Scripts/2_Analyses/Habitat_Chapter/Detection_Submodel/Model_Structure_Files/JAGS_HabDetMod2.txt",
                 parameters.to.save = c("a0", "b0", "b1", "b2", "b3", "b4"),
                 n.iter = ni, 
                 n.burnin = nb, 
                 n.chains = nc,
                 n.thin = nt,
                 parallel = TRUE,
                 inits = init_func)
# plot traceplots
tracedens_jags(sim_fit1.5, parmfrow = c(3,3))

# Get a summary of the results
summary(sim_fit1.5)
# Did we recover our parameters?
beta

# Plot posterior distribution
jags_chains1.5 <- jags_df(sim_fit1)

chains_viol1.5 <- jags_chains1.5 %>% select(b1,b2,b3,b4)
colnames(chains_viol1.5) <- c("date","veg_density","background_noise","effort")
true_vals <- data.frame(beta,covariate=c("date","veg_density","background_noise","effort"))
chains_viol_long1.5 <- chains_viol1.5 %>% pivot_longer(cols = c("date","veg_density","background_noise","effort"),names_to = "Parameter", values_to = "Values")

# Create the violin plot
plot1.5 <- ggplot() +
  geom_violin(data=chains_viol_long1, aes(x = Parameter, y = Values,fill = Parameter),trim = FALSE) +
  labs(title = "Posterior Distributions and True Parameters, Veg Density More Normal") +
  scale_fill_manual(values = c("date"=palette_5[1], "background_noise"=palette_5[2], "effort" = palette_5[3], "veg_density" = palette_5[4])) + theme(axis.text.x = element_blank())+
  geom_point(data = true_vals, aes(x=covariate, y = beta))+
  theme_minimal()
plot1.5
```


The real data that I have has NA values, either from where a vegetation survey wasn't conducted or where the ARU cut out early in the season. Let's try running the same model but with a little bit of "mess" in the data. 

## Add in NA values to the data

```{R Add in Mess and Sub Random Data for NAs}
# Now let's try the same model with some "messiness" i.e. holes for NAs in the data
# Create some holes in the samples to simulate NA data
# select randomly which data will be NA
set.seed(1)
mess_y <- sample(1:nP, 16)
sort(mess_y)
y2 <- y
# Change this data to NA
y2[mess_y, 3:6] <- NA

# Create new covariate values with some "mess" in them
db_cov2 <- db_cov
db_cov2[mess_y, 3:6] <- NA
effort_cov2 <- effort_cov
effort_cov2[mess_y, 3:6] <- NA

# Call the model again
# Create a list of data for JAGS
jags_data2 <- list(
  # True presence at sites with confirmed presences
  Z = z,
  # Detection/nondetection data
  det_data = y2,
  # Date
  cov1 = date_cov,
  # Veg Density - site level
  cov2 = veg_cov,
  # Background noise
  cov3 = db_cov2,
  # Effort 
  cov4 = effort_cov2,
  n_unit = nP,
  n_rep = nV
)
```
```{R Run JAGS Model with Mess, eval = FALSE}
# Run JAGS model
jags_fit_test_mess <- jags(data = jags_data2, 
                 model.file = "./R_Scripts/2_Analyses/Habitat_Chapter/Detection_Submodel/Model_Structure_Files/JAGS_HabDetMod2.txt",
                 parameters.to.save = c("a0", "b0", "b1", "b2", "b3", "b4"),
                 n.iter = ni, 
                 n.burnin = nb, 
                 n.chains = nc,
                 n.thin = nt,
                 parallel = TRUE,
                 inits = init_func)
#saveRDS(jags_fit_test_mess, file = "./R_Scripts/2_Analyses/Habitat_Chapter/Detection_Submodel/Models_Ran_Outputs/Simulations/Test_JAGS_RecoverParams_WMess_GlobalDetMod2.Rdata")
```

Once again, let's evaluate the convergence and outputs of the model. 
```{R Evaluate Convergence Output Sim2}
sim_fit2 <-readRDS("C:/Users/annak/OneDrive/Documents/UM/Research/Coding_Workspace/Cuckoo-Research/R_Scripts/2_Analyses/Habitat_Chapter/Detection_Submodel/Models_Ran_Outputs/Simulations/Test_JAGS_RecoverParams_WMess_GlobalDetMod2.Rdata")

# Evaluate convergence
tracedens_jags(sim_fit2, parmfrow = c(3,3))
# all of the covariates converged

# Get a summary of the results
print(sim_fit2)
# Did we recover our parameters?
beta
# Retrieved the parameters but not as well?
# Add on violin plots

chains2 <- jags_df(sim_fit2)

chains_viol2 <- chains2 %>% select(b1,b2,b3,b4)
colnames(chains_viol2) <- c("date","veg_density","background_noise","effort")
true_vals2 <- data.frame(beta,covariate=c("date","veg_density","background_noise","effort"))
chains_viol_long2 <- chains_viol2 %>% pivot_longer(cols = c("date","veg_density","background_noise","effort"),names_to = "Parameter", values_to = "Values")

# Create the violin plot
plot2 <- ggplot() +
  geom_violin(data=chains_viol_long2, aes(x = Parameter, y = Values,fill = Parameter),trim = FALSE) +
  labs(title = "Posterior Distributions w/ NAs") +
  scale_fill_manual(values = c("date"=palette_5[1], "background_noise"=palette_5[2], "effort" = palette_5[3], "veg_density" = palette_5[4])) + theme(axis.text.x = element_blank())+
  geom_point(data = true_vals2, aes(x=covariate, y = beta))+
  theme_minimal()
plot2
```

From this, it looks like the NAs are only very slightly affecting the posterior distributions, these graphs look pretty much identical to the first ones.


However, the way we treated NA values in the previous simulation was to sample from a distribution to fill them in. Another way to handle them is to simply skip over them in the model. Let's try this and see what we get. 

## Excluding NAs in Model 

```{R Excluding NAs, eval = FALSE}
get_na <- function(x){(max(which(!is.na(x))))}
# Apply this to our data
miss <- apply(y2, 1, get_na)

cat("
  model{
    # Loop through each sampling unit
    for(i in 1:n_unit){
      Z[i] ~ dbern(psi[i])  # Presence or absence drawn from a bernoulli distribution with occupancy probability psi  
      logit(psi[i]) <- a0
      
      for(j in 1:miss[i]){
        det_data[i,j] ~  dbern(Z[i]*theta[i,j])  # Create detection data drawn from a bernoulli distribution incorporating the true presence (Z) with probability of detection theta
        logit(theta[i,j]) <- b0 + b1*cov1[i,j] + b2*cov2[i] + b3*cov3[i,j] + b4*cov4[i,j]
        
      }
    }
    
    # Priors
    a0 ~ dlogis(0, 1)
    b0 ~ dlogis(0, 1)
    b1 ~ dnorm(0, 1)
    b2 ~ dnorm(0, 1)
    b3 ~ dnorm(0, 1)
    b4 ~ dnorm(0, 1)
  }
  ", file = "./R_Scripts/2_Analyses/Habitat_Chapter/Detection_Submodel/Model_Structure_Files/JAGS_HabDetMod2-SkipNA.txt")

# Create a list of data for JAGS
jags_data3 <- list(
  # True presence at sites with confirmed presences
  Z = z,
  # Detection/nondetection data
  det_data = y2,
  # Date
  cov1 = date_cov,
  # Veg Density - site level
  cov2 = veg_cov,
  # Background noise
  cov3 = db_cov2,
  # Effort 
  cov4 = effort_cov2,
  n_unit = nP,
  miss = miss
)

# Run JAGS model
jags_fit_test_mess2 <- jags(data = jags_data3, 
                 model.file = "./R_Scripts/2_Analyses/Habitat_Chapter/Detection_Submodel/Model_Structure_Files/JAGS_HabDetMod2-SkipNA.txt",
                 parameters.to.save = c("a0", "b0", "b1", "b2", "b3", "b4"),
                 n.iter = ni, 
                 n.burnin = nb, 
                 n.chains = nc,
                 n.thin = nt,
                 parallel = TRUE,
                 inits = init_func)
#saveRDS(jags_fit_test_mess2, file = "./R_Scripts/2_Analyses/Habitat_Chapter/Detection_Submodel/Models_Ran_Outputs/Simulations/Test_JAGS_RecoverParams_WMess_GlobalDetMod2-SkipNA.Rdata")
```

```{R Evaluate Convergence Outputs Sim3}
sim_fit3 <-readRDS("C:/Users/annak/OneDrive/Documents/UM/Research/Coding_Workspace/Cuckoo-Research/./R_Scripts/2_Analyses/Habitat_Chapter/Detection_Submodel/Models_Ran_Outputs/Simulations/Test_JAGS_RecoverParams_WMess_GlobalDetMod2-SkipNA.Rdata")

# Evaluate convergence
tracedens_jags(sim_fit3, parmfrow = c(3,3))
# all of the covariates converged

# Get a summary of the results
print(sim_fit3)
# Did we recover our parameters?
beta
# Retrieved the parameters but not as well?
# Add on violin plots

chains3 <- jags_df(sim_fit3)

chains_viol3 <- chains3 %>% select(b1,b2,b3,b4)
colnames(chains_viol3) <- c("date","veg_density","background_noise","effort")
true_vals3 <- data.frame(beta,covariate=c("date","veg_density","background_noise","effort"))
chains_viol_long3 <- chains_viol3 %>% pivot_longer(cols = c("date","veg_density","background_noise","effort"),names_to = "Parameter", values_to = "Values")

# Create the violin plot
plot3 <- ggplot() +
  geom_violin(data=chains_viol_long3, aes(x = Parameter, y = Values,fill = Parameter),trim = FALSE) +
  labs(title = "Posterior Distributions w/ NAs Skipped") +
  scale_fill_manual(values = c("date"=palette_5[1], "background_noise"=palette_5[2], "effort" = palette_5[3], "veg_density" = palette_5[4])) + theme(axis.text.x = element_blank())+
  geom_point(data = true_vals3, aes(x=covariate, y = beta))+
  theme_minimal()
plot3
```

It looks like skipping the NAs just pulls the posterior distribution very slightly towards the center of that distribution. It doesn't look like subbing in NAs vs just skipping the NA values makes a  difference.

### Looking at all plots together:
```{R Final Plotting, echo = FALSE, out.width = "33%"}
plot1
plot2
plot3
```

It looks like with a 15% rate of NAs (approximately what we have in our data), neither way of accounting for NAs is affecting our output significantly. Just to check that the model is working correctly, I simulated a new dataset with 50% NAs to see what affect that would have. 

```{R Add in More NAs, eval= FALSE}
# Create some holes in the samples to simulate NA data
# select randomly which data will be NA
set.seed(1)
mess_y4 <- sample(1:nP, 54)
sort(mess_y4)
# Copy over original data
y4 <- y
# Change this data to NA
y4[mess_y4, 3:6] <- NA

# Create new covariate values with some "mess" in them
db_cov4 <- db_cov
db_cov4[mess_y4, 3:6] <- NA
effort_cov4 <- effort_cov
effort_cov4[mess_y4, 3:6] <- NA

# Call the model again
# Create a list of data for JAGS
jags_data4 <- list(
  # True presence at sites with confirmed presences
  Z = z,
  # Detection/nondetection data
  det_data = y4,
  # Date
  cov1 = date_cov,
  # Veg Density - site level
  cov2 = veg_cov,
  # Background noise
  cov3 = db_cov4,
  # Effort 
  cov4 = effort_cov4,
  n_unit = nP,
  n_rep = nV
)
```
```{R Run JAGS Model with Half NAs, eval = FALSE}
# Run JAGS model
jags_mess4 <- jags(data = jags_data4, 
                 model.file = "./R_Scripts/2_Analyses/Habitat_Chapter/Detection_Submodel/Model_Structure_Files/JAGS_HabDetMod2.txt",
                 parameters.to.save = c("a0", "b0", "b1", "b2", "b3", "b4"),
                 n.iter = ni, 
                 n.burnin = nb, 
                 n.chains = nc,
                 n.thin = nt,
                 parallel = TRUE,
                 inits = init_func)
#saveRDS(jags_mess4, file = "./R_Scripts/2_Analyses/Habitat_Chapter/Detection_Submodel/Models_Ran_Outputs/Simulations/Test_JAGS_RecoverParams_WMess_GlobalDetMod2-HalfNA.Rdata")
```
```{R Evaluate Graph Half NAs}
sim_fit4 <-readRDS("C:/Users/annak/OneDrive/Documents/UM/Research/Coding_Workspace/Cuckoo-Research/./R_Scripts/2_Analyses/Habitat_Chapter/Detection_Submodel/Models_Ran_Outputs/Simulations/Test_JAGS_RecoverParams_WMess_GlobalDetMod2-HalfNA.Rdata")
# From this we should see less convergence and greater uncertainty in the estimates
tracedens_jags(sim_fit4, parmfrow = c(3,3))
chains4 <- jags_df(sim_fit4)

chains_viol4 <- chains4 %>% select(b1,b2,b3,b4)
colnames(chains_viol4) <- c("date","veg_density","background_noise","effort")
true_vals4 <- data.frame(beta,covariate=c("date","veg_density","background_noise","effort"))
chains_viol_long4 <- chains_viol4 %>% pivot_longer(cols = c("date","veg_density","background_noise","effort"),names_to = "Parameter", values_to = "Values")

# Create the violin plot
plot4 <- ggplot() +
  geom_violin(data=chains_viol_long4, aes(x = Parameter, y = Values,fill = Parameter),trim = FALSE) +
  labs(title = "Posterior Distributions w/ 50% NAs") +
  scale_fill_manual(values = c("date"=palette_5[1], "background_noise"=palette_5[2], "effort" = palette_5[3], "veg_density" = palette_5[4])) + theme(axis.text.x = element_blank())+
  geom_point(data = true_vals4, aes(x=covariate, y = beta))+
  theme_minimal()
plot4
```

It seems that once we get to very high amounts of NAs in our data (50%), the posterior distributions are pulled towards zero ever so slightly but are still relatively unaffected. I think this makes sense, since the NAs are filled in with informed data within the model, but I wuold have thought that more NAs would be more likely to highly bias our estimates. 
 

