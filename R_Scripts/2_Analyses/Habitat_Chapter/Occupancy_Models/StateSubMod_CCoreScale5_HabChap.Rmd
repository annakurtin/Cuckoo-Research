---
title: 'Occupancy Sub Model C5: Core Scale Covariates'
author: "Anna Kurtin"
date: "2024-07-30"
output: html_document
---

This is the ongoing iteration of the core home range (130 m radius of points) scale submodel within the occupancy/state submodel, after selecting which covariates to combine and which to include (see habitat modeling notes and progress in OneNote). I decided to including canopy height and veg sd residual after talking with Andy and Erim and deciding that we were interested in the different effects of these covariates - they're mathematically related but have someone related but different biological processes. I decided to remove percent canopy cover b/c it's colinear with multiple other covariates of interest and it is accounted for by percent canopy landscape (which it is also colinear with). I also removed subcan sd since it's nested within total veg sd and colinear with subcanopy height.

#### Model structure:

State model with four covariates: percent subcanopy (cova1),  height of subcanopy (cova2), height of canopy (cova3), and standard deviation of all veg residuals from regression with canopy height (cov4)

$$
z_i \sim Bernoulli(\psi | \alpha_{1}, \alpha_{2}, \alpha_{3}, \alpha_{4})
$$ 

Process model with four covariates:  

$$
y_{ij} \sim Bernoulli(p| \beta_{date}, \beta_{date}^2,\beta_{avg db}, \beta_{effort})
$$

**Handling of NAs:** omission for detections, imputation for habitat covariates

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(jagsUI)
library(rjags)
library(tidyverse)
library(jagshelper)
library(ggplot2)
library(beepr)
source("C:/Users/annak/OneDrive/Documents/UM/Research/Coding_Workspace/Cuckoo-Research/R_Scripts/5_Visualization/Create_HexCodes_CuckooColorBlind.R")
```


```{R Read in Data}
full_dat <- read.csv("C:/Users/annak/OneDrive/Documents/UM/Research/Coding_Workspace/Cuckoo-Research/Data/Habitat_Model_Covariates/HabChap_DetOccCovsFull_SCALED_7-30.csv")

detections <- full_dat[,2:7]

# Have to specify the z data for a true presence if there was a 1 at any time 
z_dat <- rowSums(detections, na.rm = T)
z_dat[z_dat > 1] <- 1
z_dat[z_dat == 0] <- NA

# get the length of non-nas in the detection data
get_na <- function(x){(max(which(!is.na(x))))}
# Apply this to our data
miss <- apply(detections, 1, get_na)
```

```{R Setup JAGS Data}
# Create a list of data for JAGS
jags_data <- list(
  # True presence at sites with confirmed presences
  Z = z_dat,
  # Detection/nondetection data
  det_data = detections,
  # percent subcanopy
  cova1 = full_dat$pct_subcan_core,
  # average height of subcanopy
  cova2 = full_dat$ht_subcan_core,
  # average height of canopy 
  cova3 = full_dat$ht_can_core,
  # residual variation in st dev of all veg regressed on canopy height
  cova4 = full_dat$veg_sd_resid,
  # Date
  covb1 = full_dat[,35:40],
  # Background noise
  covb3 = full_dat[,22:27],
  # Effort 
  covb4 = full_dat[,29:34],
  n_unit = nrow(detections),
  miss = miss
)

# Set initial values 
init_func <- function(){
  list(
    a0 = rnorm(1, 0, 1),
    a1 = rnorm(1, 0, 1),
    a2 = rnorm(1, 0, 1),
    a3 = rnorm(1, 0, 1),
    a4 = rnorm(1, 0, 1),
    b0 = rnorm(1, 0, 1),
    b1 = rnorm(1, 0, 1),
    b1Q = rnorm(1, 0 ,1),
    b3 = rnorm(1, 0, 1),
    b4 = rnorm(1, 0, 1)
  )
}
```

```{R Sub Model C5 Structure, eval = FALSE}
cat("
  model{
        # Priors
    a0 ~ dlogis(0, 1)
    a1 ~ dlogis(0, 1)
    a2 ~ dlogis(0, 1)
    a3 ~ dlogis(0, 1)
    a4 ~ dlogis(0, 1)
    b0 ~ dlogis(0, 1)
    b1 ~ dlogis(0, 1)
    b1Q ~ dlogis(0, 1)
    b3 ~ dlogis(0, 1)
    b4 ~ dlogis(0, 1)
  
    # Likelihood
    # Loop through each sampling unit
    for(i in 1:n_unit){
      # Impute missing habitat data
      cova1[i] ~ dnorm(0, 1)
      cova2[i] ~ dnorm(0, 1)
      cova3[i] ~ dnorm(0, 1)
      cova4[i] ~ dnorm(0, 1)
  
      Z[i] ~ dbern(psi[i])  # Presence or absence drawn from a bernoulli distribution with occupancy probability psi  
      logit(psi[i]) <- a0 + a1*cova1[i] + a2*cova2[i] + a3*cova3[i] + a4*cova4[i] 
      
      for(j in 1:miss[i]){
        # Impute missing detection data
        covb1[i,j] ~ dnorm(0, 1)
        covb3[i,j] ~ dnorm(0, 1)
        covb4[i,j] ~ dnorm(0, 1)
        
        det_data[i,j] ~  dbern(Z[i]*theta[i,j])  # Create detection data drawn from a bernoulli distribution incorporating the true presence (Z) with probability of detection theta
        logit(theta[i,j]) <- b0 + b1*covb1[i,j] + b1Q*(covb1[i,j]^2) + b3*covb3[i,j] + b4*covb4[i,j]
        
      }
    }
    
    # Derived parameters

    
  }
  ", file = "C:/Users/annak/OneDrive/Documents/UM/Research/Coding_Workspace/Cuckoo-Research/R_Scripts/2_Analyses/Habitat_Chapter/Occupancy_Submodel/Model_Structure_Files/JAGS_HabOccModC5.txt")

```

```{R Run Model, results = FALSE}
fit_C5 <- jags(data = jags_data, 
                 model.file = "C:/Users/annak/OneDrive/Documents/UM/Research/Coding_Workspace/Cuckoo-Research/R_Scripts/2_Analyses/Habitat_Chapter/Occupancy_Submodel/Model_Structure_Files/JAGS_HabOccModC5.txt",
                 parameters.to.save = c("a0", "a1", "a2", "a3", "a4", "b0", "b1", "b1Q", "b3", "b4"),
                 n.iter = 10000, 
                 n.burnin = 4000, 
                 n.chains = 3,
                 n.thin = 2,
                 inits = init_func)
beep(sound = 3)
```

```{R Evaluate Model}
print(fit_C5)
tracedens_jags(fit_C5, parmfrow = c(3,3))
```

```{R again plotting, echo = FALSE}
chains_c5 <- jags_df(fit_C5)

chains_alpha <- chains_c5 %>% select(a1,a2,a3,a4)
colnames(chains_alpha) <- c("% subcan cover","subcanopy height", "canopy height", "all veg sd resid")
chains_alpha_l <- chains_alpha %>% pivot_longer(cols = c("% subcan cover","subcanopy height", "canopy height", "all veg sd resid"),names_to = "Parameter", values_to = "Values")
# Create the violin plot
ggplot() +
  geom_violin(data=chains_alpha_l, aes(x = Parameter, y = Values,fill = Parameter),trim = FALSE) +
  labs(title = "Posterior Distribution of Core Area Scale Covariates") +
  scale_fill_manual(values = c("% subcan cover"=palette_8[5], "subcanopy height" = palette_8[6], "canopy height" = palette_8[7], "all veg sd resid" = palette_8[8])) + 
  geom_hline(yintercept = 0, linetype = "solid", color = "black") +
  theme_minimal()


chains_beta <- chains_c5 %>% select(b1, b1Q, b3, b4)
colnames(chains_beta) <- c("date", "quadratic date", "background dB", "effort")
chains_beta_l <- chains_beta %>% pivot_longer(cols = c("date", "quadratic date", "background dB", "effort"),names_to = "Parameter", values_to = "Values")
# Create the violin plot
ggplot() +
  geom_violin(data=chains_beta_l, aes(x = Parameter, y = Values,fill = Parameter),trim = FALSE) +
  labs(title = "Posterior Distribution of Detection Covariates") +
  scale_fill_manual(values = c("date" = palette_8[1], "quadratic date" = palette_8[2], "background dB" = palette_8[3], "effort" = palette_8[4])) + 
  geom_hline(yintercept = 0, linetype = "solid", color = "black") +
  theme_minimal()
```


The detection covariates didn't change in magnitude or direction from previous models - good!

Covariates to retain: 

* Percent subcanopy

* Subcanopy average height

* Residual variation in SD


```{R WAIC C5}
# Extract samples from the posterior
c5_s <- jags.samples(fit_C5$model,
                           c("WAIC","deviance"),
                           type = "mean",
                           n.iter = 5000,
                           n.burnin = 1000,
                           n.thin = 2)
beep()
# Duplicate WAIC samples - the WAIC is the posterior mean for that sample?
c5_s$p_waic <- c5_s$WAIC
# Calculate a new waic by adding the waic plus the deviance
c5_s$waic_calc <- c5_s$deviance + c5_s$p_waic
# Create a new vector of the sum across each array (sum WAIC, sum deviance, sum p_waic, and sum waic_calc)
tmp <- sapply(c5_s, sum)
# Pull out the sum of the WAIC we calculated and the p_waic we duplicated
waic_c5 <- round(c(waic = tmp[["waic_calc"]], p_waic = tmp[["p_waic"]]),1)
# Calculate the standard error for WAIC
c5_waic_se <- sd(c5_s$waic_calc)/(sqrt(length(c5_s$waic_calc)))
```



#### Compare with Naive Model 
```{R Setup Naive Model, echo = FALSE}
# Create a list of data for JAGS
naive_data <- list(
  # True presence at sites with confirmed presences
  Z = z_dat,
  # Detection/nondetection data
  det_data = detections,
  n_unit = nrow(detections),
  miss = miss
)

# Set initial values 
init_func_naive <- function(){
  list(
    a0 = rnorm(1, 0, 1),
    b0 = rnorm(1, 0, 1)
  )
}
```
```{R Create Naive Model, eval = FALSE}
cat("
  model{
        # Priors
    a0 ~ dlogis(0, 1)
    b0 ~ dlogis(0, 1)
  
    # Likelihood
    # Loop through each sampling unit
    for(i in 1:n_unit){
      # Impute missing habitat data
  
      Z[i] ~ dbern(psi[i])  # Presence or absence drawn from a bernoulli distribution with occupancy probability psi  
      logit(psi[i]) <- a0 
      
      for(j in 1:miss[i]){
        det_data[i,j] ~  dbern(Z[i]*theta[i,j])  # Create detection data drawn from a bernoulli distribution incorporating the true presence (Z) with probability of detection theta
        logit(theta[i,j]) <- b0
        
      }
    }
    
    # Derived parameters
    
  }
  ", file = "C:/Users/annak/OneDrive/Documents/UM/Research/Coding_Workspace/Cuckoo-Research/R_Scripts/2_Analyses/Habitat_Chapter/Occupancy_Submodel/Model_Structure_Files/JAGS_HabOccModNAIVE.txt")
```

```{R Run Naive Model, results = FALSE}
fit_naive <- jags(data = naive_data, 
                 model.file = "C:/Users/annak/OneDrive/Documents/UM/Research/Coding_Workspace/Cuckoo-Research/R_Scripts/2_Analyses/Habitat_Chapter/Occupancy_Submodel/Model_Structure_Files/JAGS_HabOccModNAIVE.txt",
                 parameters.to.save = c("a0", "b0"),
                 n.iter = 10000, 
                 n.burnin = 4000, 
                 n.chains = 3,
                 n.thin = 2,
                 #parallel = TRUE,
                 inits = init_func_naive)
beep()
```

```{R WAIC naive model}
# Extract samples from the posterior
naive_s <- jags.samples(fit_naive$model,
                           c("WAIC","deviance"),
                           type = "mean",
                           n.iter = 5000,
                           n.burnin = 1000,
                           n.thin = 2)
beep()
# Duplicate WAIC samples - the WAIC is the posterior mean for that sample?
naive_s$p_waic <- naive_s$WAIC
# Calculate a new waic by adding the waic plus the deviance
naive_s$waic_calc <- naive_s$deviance + naive_s$p_waic
# Create a new vector of the sum across each array (sum WAIC, sum deviance, sum p_waic, and sum waic_calc)
tmp <- sapply(naive_s, sum)
# Pull out the sum of the WAIC we calculated and the p_waic we duplicated
waic_naive <- round(c(waic = tmp[["waic_calc"]], p_waic = tmp[["p_waic"]]),1)
# Calculate the standard error for WAIC
naive_waic_se <- sd(naive_s$waic_calc)/(sqrt(length(naive_s$waic_calc)))
```


Compare sub model and naive model via WAIC: 

```{R Compare WAIC}
waic_c5
c5_waic_se
waic_naive
naive_waic_se
```
