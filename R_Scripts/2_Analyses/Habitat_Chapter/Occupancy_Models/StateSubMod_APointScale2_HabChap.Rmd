---
title: 'Occupancy Sub Model A2: Point Scale Covariates'
author: "Anna Kurtin"
date: "2024-08-1"
output: html_document
---


This is the second iteration of the point scale submodel (11.3 m radius of points) within the occupancy/state submodel. Based on ./R_Markdown/Evaluate_Distrib_ContCovs_ShrubComm.Rmd, the invasive shrub type has too little points, and upland is correlated with other covariates. Therefore, I will only be looking at floodplain vs non flooplain dominant shrub community. 

**Model structure:**

State model with two covariates: tree species richness and a dummy variable for dominant shrub community

$$
z_i \sim Bernoulli(\psi | \alpha_{tree spp richness}, \alpha_{floodplain shrub community})
$$ 

Process model with four covariates:  

$$
y_{ij} \sim Bernoulli(p| \beta_{date}, \beta_{date}^2,\beta_{avg db}, \beta_{effort})
$$

**Handling of NAs:** omission for detections, imputation for habitat covariates


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(jagsUI)
library(rjags)
library(tidyverse)
library(jagshelper)
library(ggplot2)
library(beepr)
source("C:/Users/annak/OneDrive/Documents/UM/Research/Coding_Workspace/Cuckoo-Research/R_Scripts/5_Visualization/Create_HexCodes_CuckooColorBlind.R")
```

```{r Read in Data}
full_dat <- read.csv("C:/Users/annak/OneDrive/Documents/UM/Research/Coding_Workspace/Cuckoo-Research/Data/Habitat_Model_Covariates/HabChap_DetOccCovsFull_SCALED_7-30.csv")

detections <- full_dat[,2:7]

# Have to specify the z data for a true presence if there was a 1 at any time 
z_dat <- rowSums(detections, na.rm = T)
z_dat[z_dat > 1] <- 1
z_dat[z_dat == 0] <- NA

# get the length of non-nas in the detection data
get_na <- function(x){(max(which(!is.na(x))))}
# Apply this to our data
miss <- apply(detections, 1, get_na)
```

```{R Setup JAGS Data}
# Create a list of data for JAGS
jags_data <- list(
  # True presence at sites with confirmed presences
  Z = z_dat,
  # Detection/nondetection data
  det_data = detections,
  # Native broadleaf tree spp richness
  cova1 = full_dat$tree_spp_rich,
  # Floodplain shrub community
  cova2 = full_dat$floodplain_shrub,
  # Date
  covb1 = full_dat[,35:40],
  # Background noise
  covb3 = full_dat[,22:27],
  # Effort 
  covb4 = full_dat[,29:34],
  n_unit = nrow(detections),
  miss = miss
)

# Set initial values 
init_func <- function(){
  list(
    a0 = rnorm(1, 0, 1),
    a1 = rnorm(1, 0, 1),
    a2 = rnorm(1, 0, 1),
    b0 = rnorm(1, 0, 1),
    b1 = rnorm(1, 0, 1),
    b1Q = rnorm(1, 0 ,1),
    b3 = rnorm(1, 0, 1),
    b4 = rnorm(1, 0, 1)
  )
}
```

```{R Sub Model A2 Structure}
cat("
  model{
        # Priors
    a0 ~ dlogis(0, 1)
    a1 ~ dlogis(0, 1)
    a2 ~ dlogis(0, 1)
    b0 ~ dlogis(0, 1)
    b1 ~ dlogis(0, 1)
    b1Q ~ dlogis(0, 1)
    b3 ~ dlogis(0, 1)
    b4 ~ dlogis(0, 1)
  
    # Likelihood
    # Loop through each sampling unit
    for(i in 1:n_unit){
      # Impute missing habitat data
      cova1[i] ~ dnorm(0, 1)
      cova2[i] ~ dnorm(0, 1)
  
      Z[i] ~ dbern(psi[i])  # Presence or absence drawn from a bernoulli distribution with occupancy probability psi  
      logit(psi[i]) <- a0 + a1*cova1[i] + a2*cova2[i]
      
      for(j in 1:miss[i]){
       # Impute missing detection data
        covb1[i,j] ~ dnorm(0, 1)
        covb3[i,j] ~ dnorm(0, 1)
        covb4[i,j] ~ dnorm(0, 1)
  
        det_data[i,j] ~  dbern(Z[i]*theta[i,j])  # Create detection data drawn from a bernoulli distribution incorporating the true presence (Z) with probability of detection theta
        logit(theta[i,j]) <- b0 + b1*covb1[i,j] + b1Q*(covb1[i,j]^2) + b3*covb3[i,j] + b4*covb4[i,j]
        
      }
    }
    
    # Derived parameters
    
  }
  ", file = "C:/Users/annak/OneDrive/Documents/UM/Research/Coding_Workspace/Cuckoo-Research/R_Scripts/2_Analyses/Habitat_Chapter/Occupancy_Submodel/Model_Structure_Files/JAGS_HabOccModA2.txt")

```

```{R Run Model, results = FALSE}
fit_A2 <- jags(data = jags_data, 
                 model.file = "C:/Users/annak/OneDrive/Documents/UM/Research/Coding_Workspace/Cuckoo-Research/R_Scripts/2_Analyses/Habitat_Chapter/Occupancy_Submodel/Model_Structure_Files/JAGS_HabOccModA2.txt",
                 parameters.to.save = c("a0", "a1", "a2", "b0", "b1", "b1Q", "b3", "b4"),
                 n.iter = 10000, 
                 n.burnin = 4000, 
                 n.chains = 3,
                 n.thin = 2,
                 inits = init_func)
beep(sound = 3)
```

```{R Evaluate Model}
print(fit_A2)
tracedens_jags(fit_A2, parmfrow = c(3,3))
```

```{R Create Violin Plots}
chains_a2 <- jags_df(fit_A2)
# Select the chains for our covariates of interest
chains_viol <- chains_a2 %>% select(a1,a2)
# Rename them to be more interpretable
colnames(chains_viol) <- c("tree spp richness", "floodplain shrub")
# Pivot this longer so that we can visualize it
chains_viol_long <- chains_viol %>% pivot_longer(cols = c("tree spp richness", "floodplain shrub"),names_to = "Parameter", values_to = "Values")

# Create the violin plot
ggplot() +
  geom_violin(data=chains_viol_long, aes(x = Parameter, y = Values,fill = Parameter),trim = FALSE) +
  labs(title = "Posterior Distribution of Point Level Covariates") +
  scale_fill_manual(values = c("tree spp richness"=palette_5[1], "floodplain shrub" = palette_5[2])) + 
  geom_hline(yintercept = 0, linetype = "solid", color = "black") +
  theme_minimal()

chains_beta <- chains_a2 %>% select(b1, b1Q, b3, b4)
colnames(chains_beta) <- c("date", "quadratic date", "background dB", "effort")
chains_beta_l <- chains_beta %>% pivot_longer(cols = c("date", "quadratic date", "background dB", "effort"),names_to = "Parameter", values_to = "Values")
# Create the violin plot
ggplot() +
  geom_violin(data=chains_beta_l, aes(x = Parameter, y = Values,fill = Parameter),trim = FALSE) +
  labs(title = "Posterior Distribution of Detection Covariates") +
  scale_fill_manual(values = c("date" = palette_8[1], "quadratic date" = palette_8[2], "background dB" = palette_8[3], "effort" = palette_8[4])) + 
  geom_hline(yintercept = 0, linetype = "solid", color = "black") +
  theme_minimal()
```

Is our standard error too large for floodplain shrub?


```{R WAIC A2}
# Extract samples from the posterior
a2_s <- jags.samples(fit_A2$model,
                           c("WAIC","deviance"),
                           type = "mean",
                           n.iter = 5000,
                           n.burnin = 1000,
                           n.thin = 2)
beep()
# Duplicate WAIC samples - the WAIC is the posterior mean for that sample?
a2_s$p_waic <- a2_s$WAIC
# Calculate a new waic by adding the waic plus the deviance
a2_s$waic_calc <- a2_s$deviance + a2_s$p_waic
# Create a new vector of the sum across each array (sum WAIC, sum deviance, sum p_waic, and sum waic_calc)
tmp <- sapply(a2_s, sum)
# Pull out the sum of the WAIC we calculated and the p_waic we duplicated
waic_a2 <- round(c(waic = tmp[["waic_calc"]], p_waic = tmp[["p_waic"]]),1)
# Calculate the standard error for WAIC
a2_waic_se <- sd(a2_s$waic_calc)/(sqrt(length(a2_s$waic_calc)))
```

#### Compare with Naive Model 
```{R Setup Naive Model, echo = FALSE}
# Create a list of data for JAGS
naive_data <- list(
  # True presence at sites with confirmed presences
  Z = z_dat,
  # Detection/nondetection data
  det_data = detections,
  n_unit = nrow(detections),
  miss = miss
)

# Set initial values 
init_func_naive <- function(){
  list(
    a0 = rnorm(1, 0, 1),
    b0 = rnorm(1, 0, 1)
  )
}
```

```{R Create Naive Model, eval = FALSE}
cat("
  model{
        # Priors
    a0 ~ dlogis(0, 1)
    b0 ~ dlogis(0, 1)
  
    # Likelihood
    # Loop through each sampling unit
    for(i in 1:n_unit){
      # Impute missing habitat data
  
      Z[i] ~ dbern(psi[i])  # Presence or absence drawn from a bernoulli distribution with occupancy probability psi  
      logit(psi[i]) <- a0 
      
      for(j in 1:miss[i]){
        det_data[i,j] ~  dbern(Z[i]*theta[i,j])  # Create detection data drawn from a bernoulli distribution incorporating the true presence (Z) with probability of detection theta
        logit(theta[i,j]) <- b0
        
      }
    }
    
    # Derived parameters
    
  }
  ", file = "C:/Users/annak/OneDrive/Documents/UM/Research/Coding_Workspace/Cuckoo-Research/R_Scripts/2_Analyses/Habitat_Chapter/Occupancy_Submodel/Model_Structure_Files/JAGS_HabOccModNAIVE.txt")
```

```{R Run Naive Model, results = FALSE}
fit_naive <- jags(data = naive_data, 
                 model.file = "C:/Users/annak/OneDrive/Documents/UM/Research/Coding_Workspace/Cuckoo-Research/R_Scripts/2_Analyses/Habitat_Chapter/Occupancy_Submodel/Model_Structure_Files/JAGS_HabOccModNAIVE.txt",
                 parameters.to.save = c("a0", "b0"),
                 n.iter = 10000, 
                 n.burnin = 4000, 
                 n.chains = 3,
                 n.thin = 2,
                 #parallel = TRUE,
                 inits = init_func_naive)
beep()
```

```{R WAIC naive model}
# Extract samples from the posterior
naive_s <- jags.samples(fit_naive$model,
                           c("WAIC","deviance"),
                           type = "mean",
                           n.iter = 5000,
                           n.burnin = 1000,
                           n.thin = 2)
beep()
# Duplicate WAIC samples - the WAIC is the posterior mean for that sample?
naive_s$p_waic <- naive_s$WAIC
# Calculate a new waic by adding the waic plus the deviance
naive_s$waic_calc <- naive_s$deviance + naive_s$p_waic
# Create a new vector of the sum across each array (sum WAIC, sum deviance, sum p_waic, and sum waic_calc)
tmp <- sapply(naive_s, sum)
# Pull out the sum of the WAIC we calculated and the p_waic we duplicated
waic_naive <- round(c(waic = tmp[["waic_calc"]], p_waic = tmp[["p_waic"]]),1)
# Calculate the standard error for WAIC
naive_waic_se <- sd(naive_s$waic_calc)/(sqrt(length(naive_s$waic_calc)))
```


Compare sub model and naive model via WAIC: 

```{R Compare WAIC}
waic_a2
a2_waic_se
waic_naive
naive_waic_se
```

